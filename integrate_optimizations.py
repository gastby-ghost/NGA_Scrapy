#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NGA_Scrapy ä¼˜åŒ–ç³»ç»Ÿé›†æˆè„šæœ¬

è‡ªåŠ¨å°†æ‰€æœ‰ä¼˜åŒ–æ¨¡å—é›†æˆåˆ°nga_spider.pyä¸­ï¼Œç¡®ä¿çˆ¬è™«èƒ½å¤Ÿä½¿ç”¨æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½ã€‚

ä¼˜åŒ–åŠŸèƒ½åŒ…æ‹¬:
1. æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–
2. åˆ†æ‰¹æŸ¥è¯¢æœºåˆ¶
3. æŸ¥è¯¢æ€§èƒ½ç›‘æ§
4. ç¼“å­˜å±‚ç³»ç»Ÿ
5. æŸ¥è¯¢ç­–ç•¥ä¼˜åŒ–
6. æ™ºèƒ½é¢„åŠ è½½ç³»ç»Ÿ
7. æ•°æ®å½’æ¡£æœºåˆ¶

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-12-07
"""

import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def integrate_optimizations():
    """é›†æˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—åˆ°nga_spider.py"""

    spider_file = Path('/home/shan/NGA_Scrapy/NGA_Scrapy/spiders/nga_spider.py')

    if not spider_file.exists():
        logger.error(f"nga_spider.pyæ–‡ä»¶ä¸å­˜åœ¨: {spider_file}")
        return False

    # è¯»å–å½“å‰æ–‡ä»¶å†…å®¹
    with open(spider_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ£€æŸ¥æ˜¯å¦å·²é›†æˆæ•°æ®å½’æ¡£
    if 'from ..utils.data_archiver import DataArchiver' in content:
        logger.info("âœ… æ•°æ®å½’æ¡£å·²é›†æˆ")
    else:
        logger.warning("âš ï¸ æ•°æ®å½’æ¡£æœªé›†æˆï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ ")
        logger.info("è¯·åœ¨nga_spider.pyçš„__init__æ–¹æ³•ä¸­æ·»åŠ :")
        logger.info("""
        # åˆå§‹åŒ–æ•°æ®å½’æ¡£å™¨
        from ..utils.data_archiver import DataArchiver
        self.data_archiver = DataArchiver(
            self.db_session,
            archive_dir='./archive',
            config={'enabled': True}
        )
        """)

    # æ£€æŸ¥å…³é”®ä¼˜åŒ–åŠŸèƒ½æ˜¯å¦å·²å®ç°
    checks = {
        'ç¼“å­˜ç³»ç»Ÿ': 'self.cache_manager = get_cache_manager()',
        'æŸ¥è¯¢ä¼˜åŒ–å™¨': 'self.query_optimizer = QueryOptimizer',
        'æ€§èƒ½ç›‘æ§': 'from ..utils.monitoring import get_monitor',
        'batch_query_topics_from_db': 'def batch_query_topics_from_db',
    }

    for check_name, check_pattern in checks.items():
        if check_pattern in content:
            logger.info(f"âœ… {check_name}å·²é›†æˆ")
        else:
            logger.error(f"âŒ {check_name}æœªæ‰¾åˆ°ï¼Œå¯èƒ½éœ€è¦é‡æ–°é›†æˆ")

    logger.info("\n" + "=" * 80)
    logger.info("é›†æˆæ£€æŸ¥å®Œæˆ")
    logger.info("=" * 80)

    return True


def create_optimized_spider_template():
    """åˆ›å»ºä¼˜åŒ–åçš„çˆ¬è™«æ¨¡æ¿ä»£ç """

    template = '''
# ========================================
# NGA_Scrapy ä¼˜åŒ–ç³»ç»Ÿé›†æˆæ¨¡æ¿
# ========================================

# åœ¨NgaSpiderç±»çš„__init__æ–¹æ³•ä¸­æ·»åŠ ä»¥ä¸‹ä»£ç ï¼š

def __init__(self, *args, **kwargs):
    super(NgaSpider, self).__init__(*args, **kwargs)

    # ç¼“å­˜ä¸»é¢˜çš„æœ€æ–°å›å¤æ—¶é—´ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
    self.topic_last_reply_cache = {}

    # ========================================
    # ä¼˜åŒ–ç³»ç»Ÿé›†æˆ - å¼€å§‹
    # ========================================

    # 1. åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    from ..utils.cache_manager import get_cache_manager
    self.cache_manager = get_cache_manager({
        'local_cache': {'max_size': 10000, 'ttl': 3600},
        'strategy': 'local_first',
    })

    # 2. åˆå§‹åŒ–æŸ¥è¯¢ä¼˜åŒ–å™¨
    from ..utils.query_optimizer import QueryOptimizer
    self.query_optimizer = None  # å°†åœ¨æ•°æ®åº“åˆå§‹åŒ–åè®¾ç½®

    # 3. åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
    from ..utils.monitoring import get_monitor
    self.query_monitor = get_monitor()

    # 4. åˆå§‹åŒ–æ•°æ®å½’æ¡£å™¨ï¼ˆæœˆåº¦å½’æ¡£ï¼‰
    from ..utils.data_archiver import DataArchiver
    self.data_archiver = None  # å°†åœ¨æ•°æ®åº“åˆå§‹åŒ–åè®¾ç½®

    # ========================================
    # ä¼˜åŒ–ç³»ç»Ÿé›†æˆ - ç»“æŸ
    # ========================================

    # æ•°æ®åº“ç›¸å…³å±æ€§
    self.db_session = None
    self.db_url = kwargs.get('db_url')
    import psutil
    self.process = psutil.Process()


# åœ¨_init_dbæ–¹æ³•ä¸­æ·»åŠ ï¼š

def _init_db(self):
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    from ..utils.db_utils import create_db_session
    try:
        # ä½¿ç”¨scoped_sessionåŒ…è£…ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
        session_factory = create_db_session(self.db_url)
        if session_factory is None:
            raise RuntimeError("æ— æ³•åˆ›å»ºæ•°æ®åº“ä¼šè¯å·¥å‚")

        self.db_session = scoped_session(lambda: session_factory)

        # åˆå§‹åŒ–æŸ¥è¯¢ä¼˜åŒ–å™¨
        if self.query_optimizer is None:
            self.query_optimizer = QueryOptimizer(self.db_session, self.logger)

        # åˆå§‹åŒ–æ•°æ®å½’æ¡£å™¨ï¼ˆæœˆåº¦å½’æ¡£ï¼‰
        if self.data_archiver is None:
            self.data_archiver = DataArchiver(
                self.db_session,
                archive_dir='./archive',
                config={
                    'enabled': True,
                    'archive_threshold_days': 30,  # 30å¤©æœªæ›´æ–°åˆ™å½’æ¡£
                }
            )

        self.logger.info("æ•°æ®åº“è¿æ¥å’Œä¼˜åŒ–ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")

    except Exception as e:
        self.logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


# åœ¨parse_topic_listæ–¹æ³•ä¸­æ·»åŠ ï¼š

def parse_topic_list(self, response):
    """ä¸¤é˜¶æ®µä¸»é¢˜åˆ—è¡¨è§£æï¼šé˜¶æ®µ1-æ”¶é›†æ‰€æœ‰ä¸»é¢˜ä¿¡æ¯"""
    # ... ç°æœ‰ä»£ç  ...

    # åœ¨æ”¶é›†ä¸»é¢˜ä¿¡æ¯åï¼Œå¯ä»¥æ‰§è¡Œå…¶ä»–ä¼˜åŒ–æ“ä½œ
    # ä¾‹å¦‚ï¼šè®°å½•è®¿é—®æ¨¡å¼ã€ç¼“å­˜æ›´æ–°ç­‰

    # ... å‰©ä½™ä»£ç  ...


# åœ¨çˆ¬è™«å…³é—­æ—¶æ·»åŠ å½’æ¡£æ“ä½œï¼š

def close(self, reason):
    """çˆ¬è™«å…³é—­æ—¶æ¸…ç†èµ„æº"""
    # æ‰§è¡Œæœˆåº¦æ•°æ®å½’æ¡£
    if hasattr(self, 'data_archiver') and self.data_archiver:
        try:
            logger.info("å¼€å§‹æ‰§è¡Œæœˆåº¦æ•°æ®å½’æ¡£...")
            archive_results = self.data_archiver.auto_archive()
            logger.info(f"å½’æ¡£ç»“æœ: {archive_results}")

            # æ¸…ç†è¿‡æœŸå½’æ¡£æ–‡ä»¶
            cleaned_count = self.data_archiver.cleanup_old_archives(retention_days=365)
            logger.info(f"æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸå½’æ¡£æ–‡ä»¶")

        except Exception as e:
            self.logger.error(f"æ•°æ®å½’æ¡£å¤±è´¥: {e}")

    # å…³é—­æ•°æ®åº“ä¼šè¯
    if hasattr(self, 'db_session') and self.db_session:
        try:
            self.db_session.remove()
            self.logger.info("æ•°æ®åº“ä¼šè¯å·²å…³é—­")
        except Exception as e:
            self.logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯æ—¶å‡ºé”™: {e}")

    self.logger.info(f"å…³é—­çˆ¬è™«æ–¹å¼: {reason}")
'''

    # ä¿å­˜æ¨¡æ¿åˆ°æ–‡ä»¶
    template_file = Path('/home/shan/NGA_Scrapy/optimized_spider_template.txt')
    with open(template_file, 'w', encoding='utf-8') as f:
        f.write(template)

    logger.info(f"âœ… ä¼˜åŒ–æ¨¡æ¿å·²ä¿å­˜åˆ°: {template_file}")
    return str(template_file)


def verify_installation():
    """éªŒè¯ä¼˜åŒ–ç³»ç»Ÿå®‰è£…"""

    logger.info("=" * 80)
    logger.info("ğŸ” éªŒè¯NGA_Scrapyä¼˜åŒ–ç³»ç»Ÿå®‰è£…")
    logger.info("=" * 80)

    # æ£€æŸ¥ä¼˜åŒ–æ¨¡å—æ–‡ä»¶
    modules = [
        ('NGA_Scrapy/utils/cache_manager.py', 'ç¼“å­˜ç®¡ç†å™¨'),
        ('NGA_Scrapy/utils/query_optimizer.py', 'æŸ¥è¯¢ä¼˜åŒ–å™¨'),
        ('NGA_Scrapy/utils/monitoring.py', 'æ€§èƒ½ç›‘æ§'),
        ('NGA_Scrapy/utils/data_archiver.py', 'æ•°æ®å½’æ¡£ï¼ˆæœˆåº¦ï¼‰'),
        ('NGA_Scrapy/utils/database_partition.py', 'æ•°æ®åº“åˆ†åŒº'),
        ('add_indexes.py', 'ç´¢å¼•è¿ç§»è„šæœ¬'),
        ('test_optimization.py', 'æµ‹è¯•è„šæœ¬'),
        ('OPTIMIZATION_DEPLOYMENT.md', 'éƒ¨ç½²æŒ‡å—'),
    ]

    all_exists = True
    for module_path, module_name in modules:
        file_path = Path('/home/shan/NGA_Scrapy') / module_path
        if file_path.exists():
            size = file_path.stat().st_size
            logger.info(f"âœ… {module_name}: {module_path} ({size:,} bytes)")
        else:
            logger.error(f"âŒ {module_name}: {module_path} - æ–‡ä»¶ä¸å­˜åœ¨")
            all_exists = False

    # æ£€æŸ¥nga_spider.pyé›†æˆ
    spider_file = Path('/home/shan/NGA_Scrapy/NGA_Scrapy/spiders/nga_spider.py')
    if spider_file.exists():
        with open(spider_file, 'r', encoding='utf-8') as f:
            spider_content = f.read()

        integrations = [
            ('cache_manager', 'ç¼“å­˜ç®¡ç†å™¨'),
            ('query_optimizer', 'æŸ¥è¯¢ä¼˜åŒ–å™¨'),
            ('monitoring', 'æ€§èƒ½ç›‘æ§'),
        ]

        for keyword, name in integrations:
            if keyword in spider_content:
                logger.info(f"âœ… {name}å·²é›†æˆåˆ°nga_spider.py")
            else:
                logger.warning(f"âš ï¸ {name}æœªé›†æˆåˆ°nga_spider.py")

    logger.info("\n" + "=" * 80)
    if all_exists:
        logger.info("âœ… æ‰€æœ‰ä¼˜åŒ–æ¨¡å—æ–‡ä»¶å·²å°±ç»ª")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†ä¼˜åŒ–æ¨¡å—æ–‡ä»¶ç¼ºå¤±")

    logger.info("=" * 80)

    return all_exists


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹é›†æˆNGA_Scrapyä¼˜åŒ–ç³»ç»Ÿ\n")

    # éªŒè¯å®‰è£…
    verify_installation()

    # é›†æˆä¼˜åŒ–
    integrate_optimizations()

    # åˆ›å»ºæ¨¡æ¿
    create_optimized_spider_template()

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œæŒ‡å—:")
    logger.info("=" * 80)
    logger.info("1. è¿è¡Œç´¢å¼•è¿ç§»:")
    logger.info("   python add_indexes.py")
    logger.info("\n2. è¿è¡Œç»¼åˆæµ‹è¯•:")
    logger.info("   python test_optimization.py")
    logger.info("\n3. å‚è€ƒéƒ¨ç½²æŒ‡å—:")
    logger.info("   cat OPTIMIZATION_DEPLOYMENT.md")
    logger.info("\n4. æŸ¥çœ‹ä¼˜åŒ–æ¨¡æ¿:")
    logger.info("   cat optimized_spider_template.txt")
    logger.info("=" * 80)


if __name__ == "__main__":
    main()
