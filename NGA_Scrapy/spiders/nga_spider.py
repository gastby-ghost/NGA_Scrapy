# # nga_spider.py
# ä»¥ä¸‹æ˜¯NGAçˆ¬è™«ä»£ç çš„åŠŸèƒ½å’Œç‰¹æ€§æ€»ç»“ï¼ŒåŸºäºè¿™äº›ä¿¡æ¯å¯ä»¥å®Œæ•´è¿˜åŸä»£ç ï¼š

# ### 1. æ ¸å¿ƒåŠŸèƒ½
# - **ä¸»é¢˜çˆ¬å–**ï¼šçˆ¬å–NGAè®ºå›æ°´åŒº(fid=-7)å‰10é¡µçš„ä¸»é¢˜åˆ—è¡¨
# - **å›å¤çˆ¬å–**ï¼šå¯¹æ¯ä¸ªä¸»é¢˜çˆ¬å–å…¶æ‰€æœ‰å›å¤å†…å®¹
# - **ç”¨æˆ·ä¿¡æ¯çˆ¬å–**ï¼šè·å–å‘å¸–ç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯
# - **å¢é‡çˆ¬å–**ï¼šé€šè¿‡æ¯”è¾ƒæ•°æ®åº“ä¸­çš„æœ€åå›å¤æ—¶é—´ï¼Œåªçˆ¬å–æ–°å†…å®¹

# ### 2. ä¸»è¦ç‰¹æ€§

# #### æ•°æ®åº“é›†æˆ
# - ä½¿ç”¨SQLAlchemy ORMè¿›è¡Œæ•°æ®åº“æ“ä½œ
# - æ”¯æŒä»å‘½ä»¤è¡Œä¼ å…¥æ•°æ®åº“URL(db_urlå‚æ•°)
# - ä½¿ç”¨scoped_sessionç¡®ä¿çº¿ç¨‹å®‰å…¨
# - è‡ªåŠ¨åˆå§‹åŒ–/å…³é—­æ•°æ®åº“è¿æ¥
# - ç¼“å­˜ä¸»é¢˜æœ€åå›å¤æ—¶é—´å‡å°‘æ•°æ®åº“æŸ¥è¯¢

# #### å¢é‡çˆ¬å–æœºåˆ¶
# - æ¯”è¾ƒç½‘é¡µæ—¶é—´ä¸æ•°æ®åº“æ—¶é—´(`is_newer`æ–¹æ³•)
# - è·³è¿‡å·²å­˜åœ¨çš„æ—§å›å¤
# - æ”¯æŒå¤šç§NGAæ—¶é—´æ ¼å¼è§£æ(`_parse_nga_time`æ–¹æ³•)

# #### æ•°æ®æå–
# - **ä¸»é¢˜ä¿¡æ¯**ï¼šæ ‡é¢˜ã€IDã€å‘å¸–äººã€å‘å¸–æ—¶é—´ã€å›å¤æ•°ã€æœ€åå›å¤æ—¶é—´ã€åˆ†åŒº
# - **å›å¤ä¿¡æ¯**ï¼šå†…å®¹ã€æ¨èå€¼ã€å›å¤æ—¶é—´ã€çˆ¶å›å¤ID
# - **ç”¨æˆ·ä¿¡æ¯**ï¼šç”¨æˆ·ç»„ã€æ³¨å†Œæ—¥æœŸç­‰

# #### æ€§èƒ½ä¼˜åŒ–
# - ä¸»é¢˜åˆ—è¡¨é¡µå¹¶è¡Œçˆ¬å–(10é¡µå¹¶å‘)
# - å›å¤åˆ†é¡µè‡ªåŠ¨å¤„ç†
# - æ•°æ®åº“æŸ¥è¯¢ç»“æœç¼“å­˜
# - è·³è¿‡æ— æ–°å›å¤çš„ä¸»é¢˜

# #### é”™è¯¯å¤„ç†
# - å…¨é¢çš„å¼‚å¸¸æ•è·(SQLAlchemyErrorç­‰)
# - æ—¶é—´è§£æå¤±è´¥å¤„ç†
# - æ•°æ®åº“è¿æ¥å¤±è´¥å¤„ç†
# - è¯¦ç»†çš„æ—¥å¿—è®°å½•

# #### ä»£ç ç»“æ„
# - ä½¿ç”¨Scrapyæ ‡å‡†Spiderç»“æ„
# - æ¨¡å—åŒ–è®¾è®¡(æ•°æ®åº“æ“ä½œåˆ†ç¦»)
# - æ¸…æ™°çš„å›è°ƒæ–¹æ³•é“¾:
#   `parse â†’ parse_topic_list â†’ parse_replies`

# ### 3. å…³é”®æ–¹æ³•

# 1. **æ•°æ®åº“ç›¸å…³**:
#    - `_init_db`: åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
#    - `get_last_reply_from_db`: æŸ¥è¯¢ä¸»é¢˜æœ€åå›å¤æ—¶é—´
#    - `close`: æ¸…ç†èµ„æº

# 2. **çˆ¬å–é€»è¾‘**:
#    - `parse`: å…¥å£ç‚¹ï¼Œç”Ÿæˆä¸»é¢˜åˆ—è¡¨é¡µè¯·æ±‚
#    - `parse_topic_list`: è§£æä¸»é¢˜åˆ—è¡¨
#    - `parse_replies`: è§£æå›å¤å†…å®¹åŠåˆ†é¡µ
#    - `parse_user`: è§£æç”¨æˆ·ä¿¡æ¯(å½“å‰è¢«æ³¨é‡Š)

# 3. **å·¥å…·æ–¹æ³•**:
#    - `is_newer`: æ—¶é—´æ¯”è¾ƒ
#    - `_parse_nga_time`: æ—¶é—´æ ¼å¼è§£æ
#    - `_now_time`: è·å–å½“å‰æ—¶é—´

# ### 4. æ•°æ®æ¨¡å‹
# ä½¿ç”¨ä¸‰ä¸ªScrapy Item:
# - `TopicItem`: å­˜å‚¨ä¸»é¢˜ä¿¡æ¯
# - `ReplyItem`: å­˜å‚¨å›å¤ä¿¡æ¯
# - `UserItem`: å­˜å‚¨ç”¨æˆ·ä¿¡æ¯

# ### 5. é…ç½®å‚æ•°
# - `name = 'nga'`
# - `allowed_domains = ['bbs.nga.cn']`
# - `start_urls`: æ°´åŒºé¦–é¡µ
# - æ”¯æŒä»å‘½ä»¤è¡Œä¼ å…¥`db_url`

# ### 6. æ€§èƒ½è€ƒè™‘
# - æ•°æ®åº“ä¼šè¯ç®¡ç†(scoped_session)
# - å‡å°‘ä¸å¿…è¦çš„è¯·æ±‚(é€šè¿‡æ—¶é—´æ¯”è¾ƒ)
# - å¹¶å‘çˆ¬å–å¤šä¸ªä¸»é¢˜é¡µ
# - ç¼“å­˜æœºåˆ¶å‡å°‘æ•°æ®åº“æŸ¥è¯¢

# ### 7. å¾…ä¼˜åŒ–ç‚¹
# - ç”¨æˆ·ä¿¡æ¯çˆ¬å–å½“å‰è¢«æ³¨é‡Š
# - å¯æ·»åŠ è¯·æ±‚å»¶è¿Ÿæ§åˆ¶
# - å¯å¢åŠ ä»£ç†æ”¯æŒ
# - å¯æ·»åŠ æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

import scrapy
from scrapy import Request
from ..items import TopicItem, ReplyItem, UserItem
from urllib.parse import parse_qs, urljoin
import time
from datetime import datetime
from sqlalchemy.orm import scoped_session
from sqlalchemy.exc import SQLAlchemyError
from ..models import Base  # ç¡®ä¿å¯¼å…¥Base
import psutil
import os

class NgaSpider(scrapy.Spider):
    name = 'nga'
    allowed_domains = ['bbs.nga.cn']
    start_urls = ['https://bbs.nga.cn/thread.php?fid=-7']

    def __init__(self, *args, **kwargs):
        super(NgaSpider, self).__init__(*args, **kwargs)
        # ä¸å†åœ¨å¯åŠ¨æ—¶æ¸…ç©ºæ—¥å¿—æ–‡ä»¶ï¼Œè®©Scrapyçš„æ—¥å¿—è½®è½¬æœºåˆ¶å¤„ç†
        # è°ƒåº¦å™¨éœ€è¦è¯»å–æ—¥å¿—æ–‡ä»¶è·å–ç»Ÿè®¡ä¿¡æ¯ï¼Œæ¸…ç©ºä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±

        # ç¼“å­˜ä¸»é¢˜çš„æœ€æ–°å›å¤æ—¶é—´ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
        self.topic_last_reply_cache = {}
        # æ•°æ®åº“ç›¸å…³å±æ€§
        self.db_session = None
        self.db_url = kwargs.get('db_url')  # å…è®¸ä»å‘½ä»¤è¡Œä¼ å…¥db_url
        self.process = psutil.Process(os.getpid())  # åˆå§‹åŒ–ç›‘æ§
    
    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(NgaSpider, cls).from_crawler(crawler, *args, **kwargs)
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        spider._init_db()
        return spider
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        from ..utils.db_utils import create_db_session
        try:
            # ä½¿ç”¨scoped_sessionåŒ…è£…ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
            session_factory = create_db_session(self.db_url)
            if session_factory is None:
                raise RuntimeError("æ— æ³•åˆ›å»ºæ•°æ®åº“ä¼šè¯å·¥å‚")
            
            self.db_session = scoped_session(lambda: session_factory)
            self.logger.info("æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def close(self, reason):
        """çˆ¬è™«å…³é—­æ—¶æ¸…ç†èµ„æº"""
        if hasattr(self, 'db_session') and self.db_session:
            try:
                self.db_session.remove()
                self.logger.info("æ•°æ®åº“ä¼šè¯å·²å…³é—­")
            except Exception as e:
                self.logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯æ—¶å‡ºé”™: {e}")
        self.logger.info(f"å…³é—­çˆ¬è™«æ–¹å¼: {reason}")
        #super().close(reason)
    
    def print_stats(self):
        """æ‰“å°è¿›åº¦å’Œæ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        cpu = self.process.cpu_percent(interval=1)
        mem = self.process.memory_info().rss / 1024 / 1024
        self.logger.debug(f"ğŸ“Š CPU: {cpu}% | Memory: {mem:.2f} MB")

        # è·å–æ•°æ®åº“ç»Ÿè®¡
        if self.db_session:
            try:
                from ..models import Topic, Reply, User
                topic_count = self.db_session.query(Topic).count()
                reply_count = self.db_session.query(Reply).count()
                user_count = self.db_session.query(User).count()
                self.logger.debug(f"ğŸ“ˆ DBç»Ÿè®¡: ä¸»é¢˜={topic_count}, å›å¤={reply_count}, ç”¨æˆ·={user_count}")
            except Exception as e:
                self.logger.debug(f"âš ï¸ è·å–æ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {e}")

    def parse(self, response):
        # è§£æä¸»é¢˜åˆ—è¡¨é¡µ
        pageNum = 11
        self.logger.info(f"ğŸš€ å¼€å§‹çˆ¬å–NGAè®ºå›æ°´åŒºï¼Œå…±éœ€çˆ¬å– {pageNum-1} é¡µä¸»é¢˜åˆ—è¡¨")
        for page in range(1, pageNum):  # çˆ¬å–å‰pageNumé¡µ
            self.logger.debug(f"ğŸ“„ ç”Ÿæˆç¬¬ {page} é¡µä¸»é¢˜åˆ—è¡¨é¡µè¯·æ±‚")
            yield Request(
                url=f"https://bbs.nga.cn/thread.php?fid=-7&page={page}",
                callback=self.parse_topic_list,
                meta={'page': page}
            )

    def parse_topic_list(self, response):
        # è§£æä¸»é¢˜åˆ—è¡¨
        page = response.meta.get('page', 'unknown')
        self.logger.debug(f"ğŸ“ å¼€å§‹è§£æç¬¬ {page} é¡µä¸»é¢˜åˆ—è¡¨ (URL: {response.url})")

        rows = response.xpath('//*[contains(@class, "topicrow")]')
        self.logger.debug(f"ğŸ“Š ç¬¬ {page} é¡µä¸»é¢˜åˆ—è¡¨å…±æ‰¾åˆ° {len(rows)} ä¸ªä¸»é¢˜")

        for idx, row in enumerate(rows, 1):
            self.logger.debug(f"ğŸ” å¼€å§‹å¤„ç†ç¬¬ {page} é¡µç¬¬ {idx} ä¸ªä¸»é¢˜")
            topic_link = row.xpath('.//a[contains(@class, "topic")]/@href').get()
            if not topic_link or 'tid=' not in topic_link:
                continue
                
            tid = topic_link.split('tid=')[1].split('&')[0]
            title = row.xpath('.//a[contains(@class, "topic")]/text()').get()
            if title == 'å¸–å­å‘å¸ƒæˆ–å›å¤æ—¶é—´è¶…è¿‡é™åˆ¶':
                continue
                
            poster_id = row.xpath('.//*[@class="author"]/@title').re_first(r'ç”¨æˆ·ID (\d+)')
            post_time = row.xpath('.//span[contains(@class, "postdate")]/@title').get()
            re_num = row.xpath('.//*[@class="replies"]/text()').get()

            # ã€å¢å¼ºã€‘å¤šç§æ–¹å¼æå–æœ€åå›å¤æ—¶é—´
            last_reply_date = None

            # æ–¹å¼1: ä» .replydate çš„ title å±æ€§æå–
            last_reply_date = row.xpath('.//a[contains(@class, "replydate")]/@title').get()

            # æ–¹å¼2: ä» .replydate çš„æ–‡æœ¬å†…å®¹æå–ï¼ˆç›¸å¯¹æ—¶é—´ï¼‰
            if not last_reply_date:
                alt_date = row.xpath('.//a[contains(@class, "replydate")]/text()').get()
                if alt_date and alt_date not in ['åˆšæ‰', 'ä»Šå¤©', 'æ˜¨å¤©', 'å‰å¤©']:
                    last_reply_date = alt_date

            # æ–¹å¼3: æŸ¥æ‰¾æ‰€æœ‰æœ‰titleå±æ€§çš„å…ƒç´ ï¼Œç­›é€‰å‡ºæ—¶é—´æ ¼å¼çš„
            if not last_reply_date:
                time_candidates = row.xpath('.//*[@title and string-length(@title) > 8]/@title').getall()
                for candidate in time_candidates:
                    if self._is_nga_time_format(candidate):
                        last_reply_date = candidate
                        break

            # æ–¹å¼4: ä½¿ç”¨æ­£åˆ™ä»æ•´è¡Œæ–‡æœ¬ä¸­æå–æ—¶é—´
            if not last_reply_date:
                row_text = row.xpath('string(.)').get()
                last_reply_date = self._extract_time_from_text(row_text)

            # è·å–æ•°æ®åº“ä¸­è¯¥ä¸»é¢˜çš„æœ€åå›å¤æ—¶é—´
            self.logger.debug(f"ğŸ” ä¸»é¢˜ {tid}: æŸ¥è¯¢æ•°æ®åº“è·å–æœ€åå›å¤æ—¶é—´")
            db_last_reply = self.get_last_reply_from_db(tid)
            self.topic_last_reply_cache[tid] = db_last_reply  # å­˜å…¥ç¼“å­˜
            self.logger.debug(f"ğŸ“… ä¸»é¢˜ {tid}: æ•°æ®åº“è®°å½•æ—¶é—´ = {db_last_reply}, ç½‘é¡µæ—¶é—´ = {last_reply_date}")

            # åªæœ‰å½“ç½‘é¡µæ—¶é—´æ¯”æ•°æ®åº“æ—¶é—´æ–°æ—¶æ‰å¤„ç†
            # æ³¨æ„ï¼šå¦‚æœç½‘é¡µæ—¶é—´ä¸ºNoneï¼ˆè§£æå¤±è´¥ï¼‰ï¼Œé»˜è®¤å½“ä½œæ–°ä¸»é¢˜å¤„ç†
            if db_last_reply and last_reply_date and not self.is_newer(last_reply_date, db_last_reply):
                # ç½‘é¡µæ—¶é—´å’Œæ•°æ®åº“æ—¶é—´éƒ½å­˜åœ¨ï¼Œä½†ç½‘é¡µä¸æ–°äºæ•°æ®åº“
                self.logger.info(f"ä¸»é¢˜ {tid} æ²¡æœ‰æ–°å›å¤ (æ•°æ®åº“:{db_last_reply} >= ç½‘é¡µ:{last_reply_date})")
                continue

            # å¦‚æœç½‘é¡µæ—¶é—´ä¸ºNoneï¼ˆæ–°ä¸»é¢˜æˆ–æ— å›å¤ä¸»é¢˜ï¼‰æˆ–æ—¶é—´æ¯”æ•°æ®åº“æ–°ï¼Œç»§ç»­å¤„ç†
            if not last_reply_date:
                if db_last_reply:
                    # ä¸»é¢˜æ²¡æœ‰ç½‘é¡µæ—¶é—´ï¼Œä½†æ•°æ®åº“ä¸­æœ‰è®°å½•ï¼ˆå¯èƒ½æ˜¯è¢«é™åˆ¶æˆ–ç‰¹æ®Šä¸»é¢˜ï¼‰
                    self.logger.debug(f"âš ï¸  ä¸»é¢˜ {tid} æ— æ³•è·å–ç½‘é¡µæ—¶é—´ï¼Œæ•°æ®åº“å·²æœ‰è®°å½• (æ•°æ®åº“:{db_last_reply})")
                else:
                    # æ–°ä¸»é¢˜ï¼Œæ²¡æœ‰æœ€åå›å¤æ—¶é—´
                    self.logger.debug(f"âœ… ä¸»é¢˜ {tid} æ²¡æœ‰æœ€åå›å¤æ—¶é—´ï¼Œå½“ä½œæ–°ä¸»é¢˜å¤„ç†")
            elif db_last_reply:
                # æ—¢æœ‰ç½‘é¡µæ—¶é—´ä¹Ÿæœ‰æ•°æ®åº“æ—¶é—´
                self.logger.debug(f"âœ… ä¸»é¢˜ {tid} ç½‘é¡µæ—¶é—´æ¯”æ•°æ®åº“æ—¶é—´æ–° (ç½‘é¡µ:{last_reply_date} > æ•°æ®åº“:{db_last_reply})")
                
            partition = 'æ°´åŒº'
            partition_el = row.xpath('.//td[@class="c2"]/span[@class="titleadd2"]/a[@class="silver"]/text()')
            if partition_el:
                partition = partition_el.get()
                
            topic_item = TopicItem(
                tid=tid,
                title=title,
                poster_id=poster_id,
                post_time=post_time,
                re_num=re_num,
                sampling_time=self._now_time(),
                last_reply_date=last_reply_date,
                partition=partition
            )
            yield topic_item
            #self.print_stats() 
            #self.logger.info(f"å‡†å¤‡è·å–ä¸»é¢˜ {tid} æ‰€æœ‰å¯¹åº”ç”¨æˆ·")
            # è¯·æ±‚ç”¨æˆ·ä¿¡æ¯ 
            if poster_id:
                user_item=UserItem(
                        uid=poster_id,
                        user_group='',
                        reg_date='',
                        prestige='',
                        history_re_num='')
                yield user_item
            '''
            yield Request(
                url=f"https://bbs.nga.cn/nuke.php?func=ucp&uid={poster_id}",
                callback=self.parse_user,
                meta={'uid': poster_id},
                dont_filter=False
            )'''
            #self.print_stats() 
            # è¯·æ±‚å›å¤é¡µ
            yield Request(
                url=f"https://bbs.nga.cn/read.php?tid={tid}&page=999",
                callback=self.parse_replies,
                meta={'tid': tid, 'db_last_reply': db_last_reply}
            )
            #self.print_stats()
            self.logger.debug(f"âœ… ä¸»é¢˜ {tid}: å·²ç”Ÿæˆæ‰€æœ‰è¯·æ±‚")

        # ä¸»é¢˜åˆ—è¡¨é¡µå¤„ç†å®Œæˆ
        self.logger.debug(f"ğŸ“„ ç¬¬ {page} é¡µä¸»é¢˜åˆ—è¡¨è§£æå®Œæˆï¼Œå…±å¤„ç† {idx} ä¸ªä¸»é¢˜")

    def get_last_reply_from_db(self, tid):
        """ä»æ•°æ®åº“è·å–ä¸»é¢˜çš„æœ€åå›å¤æ—¶é—´"""
        if not hasattr(self, 'db_session') or not self.db_session:
            self.logger.error("æ•°æ®åº“ä¼šè¯æœªåˆå§‹åŒ–")
            return None
            
        try:
            from ..models import Topic  # å±€éƒ¨å¯¼å…¥é¿å…å¾ªç¯å¼•ç”¨
            topic = self.db_session.query(Topic).filter_by(tid=tid).first()
            return topic.last_reply_date if topic else None
        except SQLAlchemyError as e:
            self.logger.error(f"æŸ¥è¯¢æ•°æ®åº“å‡ºé”™: {e}")
            return None
        except Exception as e:
            self.logger.error(f"è·å–æœ€åå›å¤æ—¶é—´æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
            return None

    # å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜...
    def parse_replies(self, response):
        tid = response.meta['tid']
        db_last_reply = response.meta.get('db_last_reply')
        current_page = response.meta.get('current_page', 'unknown')
        last_page = response.meta.get('last_page', 'unknown')

        self.logger.debug(f"ğŸ’¬ å¼€å§‹è§£æä¸»é¢˜ {tid} çš„å›å¤ (å½“å‰é¡µ: {current_page}/{last_page}, URL: {response.url})")

        meta={'tid': tid}

        if 'last_page' not in response.meta:
            last_page_link = response.xpath('//a[contains(@class, "invert") and @title="æœ€åé¡µ"]/@href').get()
            if last_page_link:
                last_page = int(parse_qs(last_page_link.split('?')[1]).get('page', [1])[0])
                #self.logger.info(f"æœ€åä¸€é¡µ{last_page}è·å–")
            else:
                page_links = [int(p.split('=')[-1]) for p in response.xpath('//a[contains(@href, "page=")]/@href').re(r'page=\d+')]
                last_page = max(page_links) if page_links else 1

            meta['last_page'] = last_page
            meta['current_page'] = last_page

        if 'current_page' in response.meta:
            meta['current_page'] = response.meta['current_page']

        new_page_flag=True

        replies = response.xpath('//*[@class="forumbox postbox"]')
        self.logger.debug(f"ğŸ“œ ä¸»é¢˜ {tid}: å½“å‰é¡µ {current_page}/{last_page} å…±æœ‰ {len(replies)} æ¡å›å¤")

        for idx, reply in enumerate(replies, 1):
            self.logger.debug(f"ğŸ“ ä¸»é¢˜ {tid}: å¼€å§‹å¤„ç†ç¬¬ {idx} æ¡å›å¤ (å½“å‰é¡µ {current_page}/{last_page})")
            post_id = reply.xpath('.//*[starts-with(@id, "postcontainer")]/a[1]/@id').get()

            # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæ— æ³•è·å– post_idï¼Œè·³è¿‡è¯¥å›å¤
            if not post_id:
                self.logger.warning(f"æ— æ³•è·å– post_idï¼Œè·³è¿‡è¯¥å›å¤ (tid={tid})")
                continue

            # ç»Ÿä¸€ä½¿ç”¨çº¯æ•°å­—æ ¼å¼
            if post_id == 'pid0Anchor':
                # ä¸»æ¥¼ä½¿ç”¨ tid ä½œä¸º ridï¼Œçº¯æ•°å­—æ ¼å¼
                post_id = tid
            elif 'pid' in post_id and 'Anchor' in post_id:
                # æ™®é€šå›å¤ï¼šä» Anchor æ ¼å¼æå–çº¯æ•°å­—
                # ä¾‹å¦‚ï¼špid849526462Anchor â†’ 849526462
                post_id = post_id.replace('pid', '').replace('Anchor', '')
            elif post_id.isdigit():
                # å·²ç»æ˜¯çº¯æ•°å­—æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                pass
            else:
                # å…¶ä»–æœªçŸ¥æ ¼å¼ï¼Œè®°å½•è­¦å‘Šå¹¶è·³è¿‡
                self.logger.warning(f"æœªçŸ¥çš„ post_id æ ¼å¼: {post_id} (tid={tid})")
                continue
                
            poster_href = reply.xpath('.//*[starts-with(@id, "postauthor")]/@href').get()
            poster_id = poster_href.split('uid=')[1].split('&')[0] if poster_href and 'uid=' in poster_href else ''
            
            content = reply.xpath('.//*[starts-with(@id, "postcontent") '
                                 'and string-length(translate(substring(@id, 12), "0123456789", "")) = 0]/text()').get()
            
            recommendvalue = reply.xpath('.//span[contains(@class,"recommendvalue")]/text()').get('0')
            post_time = reply.xpath('.//*[starts-with(@id, "postdate")]/text()').get()
            
            # å¦‚æœè®¾ç½®äº†æ•°æ®åº“æœ€åå›å¤æ—¶é—´ï¼Œä¸”å½“å‰å›å¤æ—¶é—´ä¸æ–°äºæ•°æ®åº“è®°å½•ï¼Œåˆ™è·³è¿‡
            if db_last_reply and not self.is_newer(post_time, db_last_reply):
                self.logger.debug(f"è·³è¿‡å›å¤ {post_id}ï¼Œå›å¤æ—¶é—´ {post_time} ä¸æ–°äºæ•°æ®åº“è®°å½• {db_last_reply}")
                new_page_flag=False
                continue
            
            parent_rid = None
            if reply.xpath('.//div[contains(@class, "quote")]'):
                quote_link = reply.xpath('.//a[contains(@title, "æ‰“å¼€é“¾æ¥")]/@href').get()
                if quote_link and 'pid=' in quote_link:
                    parent_rid = quote_link.split('pid=')[1].split('&')[0]
            
            # æ–°å¢å›¾ç‰‡URLæå–é€»è¾‘
            image_urls = []
            # æå–æ‰€æœ‰imgæ ‡ç­¾çš„srcå±æ€§ï¼ˆåŒ…å«data-srcorgå¤‡ç”¨ï¼‰
            for img in reply.xpath('.//img'):
                src = img.xpath('@src').get()
                if src and ('attachments' in src or 'smile' in src):
                    image_urls.append(src)

            reply_item = ReplyItem(
                rid=post_id,
                tid=tid,
                parent_rid=parent_rid,
                content=content,
                recommendvalue=recommendvalue,
                post_time=post_time,
                poster_id=poster_id,
                sampling_time=self._now_time(),
                image_urls=image_urls  # æ·»åŠ å›¾ç‰‡URLåˆ—è¡¨
            )
            self.logger.debug(f"âœ… ä¸»é¢˜ {tid}: æˆåŠŸæå–å›å¤ {post_id} (æ—¶é—´: {post_time}, ç”¨æˆ·: {poster_id}, æ¨èå€¼: {recommendvalue})")
            yield reply_item

            # è¯·æ±‚ç”¨æˆ·ä¿¡æ¯
            if poster_id:
                self.logger.debug(f"ğŸ‘¤ ä¸»é¢˜ {tid}: ä¸ºç”¨æˆ· {poster_id} ç”ŸæˆUserItem")
                user_item=UserItem(
                    uid=poster_id,
                    user_group='',
                    reg_date='',
                    prestige='',
                    history_re_num='')
                yield user_item
                '''
                yield Request(
                    url=f"https://bbs.nga.cn/nuke.php?func=ucp&uid={poster_id}",
                    callback=self.parse_user,
                    meta={'uid': poster_id},
                    dont_filter=False
                )'''

        self.logger.debug(f"ğŸ“„ ä¸»é¢˜ {tid}: é¡µé¢ {current_page}/{last_page} è§£æå®Œæˆï¼Œå‡†å¤‡å¤„ç†ä¸Šä¸€é¡µ")
        # å¤„ç†ä¸Šä¸€é¡µ
        if new_page_flag and meta['current_page'] > 1:
            meta['current_page'] = meta['current_page'] - 1
            self.logger.debug(f"â¬…ï¸ ä¸»é¢˜ {tid}: ç¿»åˆ°ä¸Šä¸€é¡µ {meta['current_page']} é¡µ")
            yield Request(
                url=f"https://bbs.nga.cn/read.php?tid={tid}&page={meta['current_page']}",
                callback=self.parse_replies,
                meta=meta
            )
        else:
            self.logger.debug(f"âœ… ä¸»é¢˜ {tid}: æ‰€æœ‰å›å¤é¡µå¤„ç†å®Œæˆ")

    # å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜...
    def parse_user(self, response):
        uid = response.meta['uid']
        user_group = response.xpath('//label[contains(text(), "ç”¨â€‚æˆ·â€‚ç»„")]/../span/span/text()').get('åŒ¿åç”¨æˆ·')
        reg_date = response.xpath('//label[contains(text(), "æ³¨å†Œæ—¥æœŸ")]/../span/text()').get()
        
        user_item=UserItem(
            uid=uid,
            user_group=user_group,
            reg_date=reg_date,
            prestige='',
            history_re_num='')
        yield user_item

    def is_newer(self, time1, time2):
        """æ¯”è¾ƒä¸¤ä¸ªæ—¶é—´å­—ç¬¦ä¸²ï¼Œåˆ¤æ–­time1æ˜¯å¦æ¯”time2æ–°"""
        try:
            # å¤„ç†NGAçš„æ—¶é—´æ ¼å¼å¯èƒ½ä¸ä¸€è‡´çš„æƒ…å†µ
            dt1 = self._parse_nga_time(time1)
            dt2 = self._parse_nga_time(time2)
            self.logger.debug(f"æ—¶é—´æ¯”è¾ƒ:  time1: {dt1}, time2: {dt2}ï¼Œç»“æœï¼š{dt1 >= dt2}")
            return dt1 >= dt2
        except Exception as e:
            self.logger.error(f"æ—¶é—´æ¯”è¾ƒé”™è¯¯: {e}, web_time: {time1}, db_time: {time2}")
            return True  # å¦‚æœè§£æå¤±è´¥ï¼Œé»˜è®¤å¤„ç†ä¸ºæ–°å›å¤

    def _parse_nga_time(self, time_str):
        """è§£æNGAçš„å„ç§æ—¶é—´æ ¼å¼"""
        if not time_str:
            return datetime.min
        
        # å°è¯•å¸¸è§æ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        formats = [
            '%Y-%m-%d %H:%M:%S',  # æ ‡å‡†æ ¼å¼ 2025-04-19 17:00:00
            '%y-%m-%d %H:%M:%S',  # ç®€å†™å¹´ä»½ 25-04-19 17:00:00
            '%d-%m-%y %H:%M:%S',  # æ—¥-æœˆ-å¹´ 19-04-25 17:00:00
            '%Y-%m-%d %H:%M',     # ç¼ºå°‘ç§’
            '%y-%m-%d %H:%M',     # ç®€å†™å¹´ä»½ç¼ºå°‘ç§’
            '%d-%m-%y %H:%M',     # æ—¥-æœˆ-å¹´ç¼ºå°‘ç§’
            '%m-%d %H:%M',        # ç¼ºå°‘å¹´å’Œç§’
            '%H:%M:%S',           # åªæœ‰æ—¶é—´
            '%H:%M'               # åªæœ‰å°æ—¶å’Œåˆ†é’Ÿ
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(time_str, fmt)
            except ValueError:
                continue
        
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›æœ€å°æ—¶é—´
        self.logger.warning(f"æ— æ³•è§£æçš„æ—¶é—´æ ¼å¼: {time_str}")
        return datetime.min


    def _is_nga_time_format(self, time_str):
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºNGAæ—¶é—´æ ¼å¼"""
        if not time_str:
            return False
        import re
        # åŒ¹é… NGA æ—¶é—´æ ¼å¼: 25-11-30 15:59, 2025-11-30 15:59:30 ç­‰
        patterns = [
            r'\d{2,4}-\d{2}-\d{2}\s+\d{2}:\d{2}(?::\d{2})?',  # æ ‡å‡†æ ¼å¼
            r'\d{2,4}-\d{2}-\d{2}\s+\d{2}:\d{2}',             # ç®€åŒ–æ ¼å¼
        ]
        for pattern in patterns:
            if re.match(pattern, time_str.strip()):
                return True
        return False

    def _extract_time_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¶é—´"""
        if not text:
            return None
        import re
        # å¤šç§æ—¶é—´æ ¼å¼çš„æ­£åˆ™è¡¨è¾¾å¼
        patterns = [
            r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',  # 2025-11-30 15:59:30
            r'(\d{2}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',  # 25-11-30 15:59:30
            r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2})',        # 2025-11-30 15:59
            r'(\d{2}-\d{2}-\d{2}\s+\d{2}:\d{2})',        # 25-11-30 15:59
        ]
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)
        return None

    def _now_time(self):
        return time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())
