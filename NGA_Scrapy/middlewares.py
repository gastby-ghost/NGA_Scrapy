import scrapy
import json
import os
import time
import threading
import uuid
import logging
import sys
from queue import Queue, Empty
from typing import Optional, Dict, List, Callable, Any
from playwright.sync_api import TimeoutError as PlaywrightTimeoutError, sync_playwright
from scrapy.exceptions import NotConfigured
from scrapy import signals
from NGA_Scrapy.utils.proxy_manager import get_proxy_manager
from NGA_Scrapy.utils.ban_detector import BanDetector
from NGA_Scrapy.utils.instance_manager import BrowserInstanceManager


# ========== é…ç½®å¸¸é‡ ==========
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'Cache-Control': 'no-cache',
    'Pragma': 'no-cache',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Sec-Fetch-User': '?1',
    'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
    'Sec-Ch-Ua-Mobile': '?0',
    'Sec-Ch-Ua-Platform': '"Linux"',
    'Upgrade-Insecure-Requests': '1'
}

BROWSER_ARGS = [
    '--disable-gpu',
    '--no-sandbox',
    '--disable-dev-shm-usage',
    '--disable-extensions',
    '--disable-infobars',
    '--disable-notifications',
]

DEFAULT_VIEWPORT = {'width': 1920, 'height': 1080}
REQUEST_TIMEOUT = 60
NAV_TIMEOUT = 15000
LOAD_TIMEOUT = 5000


# ========== å·¥å…·ç±» ==========
class PerformanceStats:
    """ç®€åŒ–çš„æ€§èƒ½ç»Ÿè®¡å·¥å…·ç±»"""
    def __init__(self):
        self._lock = threading.Lock()
        self._start_time = time.time()
        self.reset()

    def reset(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        with self._lock:
            self.request_count = 0
            self.success_count = 0
            self.failed_count = 0
            self.total_page_time = 0.0
            self.max_page_time = 0.0
            self.min_page_time = float('inf')
            self.browser_recycles = 0
            self.timeout_errors = 0

    def log_request(self, success: bool, duration: float):
        """è®°å½•è¯·æ±‚ç»Ÿè®¡"""
        with self._lock:
            self.request_count += 1
            if success:
                self.success_count += 1
                self.total_page_time += duration
                self.max_page_time = max(self.max_page_time, duration)
                self.min_page_time = min(self.min_page_time, duration)
            else:
                self.failed_count += 1

    def log_recycle(self):
        """è®°å½•å®ä¾‹å›æ”¶"""
        with self._lock:
            self.browser_recycles += 1

    def log_timeout(self):
        """è®°å½•è¶…æ—¶äº‹ä»¶"""
        with self._lock:
            self.timeout_errors += 1

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            uptime = time.time() - self._start_time
            avg_time = (self.total_page_time / self.success_count) if self.success_count > 0 else 0

            return {
                'uptime': f"{uptime:.1f}s",
                'requests': self.request_count,
                'success_rate': f"{(self.success_count / self.request_count * 100):.2f}%" if self.request_count > 0 else "0%",
                'avg_page_time': f"{avg_time:.3f}s",
                'max_page_time': f"{self.max_page_time:.3f}s",
                'min_page_time': f"{self.min_page_time:.3f}s" if self.min_page_time != float('inf') else "N/A",
                'browser_recycles': self.browser_recycles,
                'timeout_errors': self.timeout_errors,
                'req_per_minute': f"{(self.request_count / (uptime / 60)):.2f}" if uptime > 0 else "N/A"
            }


# ========== Cookieç®¡ç† ==========
class CookieManager:
    """Cookieç®¡ç†å™¨ - ç‹¬ç«‹èŒè´£"""
    def __init__(self, logger):
        self.logger = logger
        self.cookies = None

    def load(self, cookies_file: str = 'cookies.txt') -> Optional[List[Dict]]:
        """åŠ è½½å¹¶é¢„å¤„ç†cookies"""
        if not os.path.exists(cookies_file):
            self.logger.info(f"Cookies file not found: {cookies_file}")
            return None

        try:
            with open(cookies_file, 'r', encoding='utf-8') as f:
                cookies = json.load(f)

            processed = []
            for c in cookies:
                try:
                    expiry = c.get('expiry') or c.get('expirationDate')
                    if expiry is None:
                        expiry = int(time.time()) + 3600
                    elif isinstance(expiry, float):
                        expiry = int(expiry)

                    domain = c.get('domain', '.ngabbs.com')
                    if not domain.startswith('.'):
                        domain = f'.{domain}'

                    cookie_dict = {
                        'name': c['name'],
                        'value': c['value'],
                        'domain': domain,
                        'path': c.get('path', '/'),
                        'expires': expiry,
                        'httpOnly': c.get('httpOnly', False),
                        'secure': c.get('secure', False),
                        'sameSite': 'Lax'
                    }

                    processed.append({k: v for k, v in cookie_dict.items() if v is not None})
                except KeyError:
                    self.logger.warning(f"Skip invalid cookie: missing required field")
                    continue

            self.cookies = processed
            return processed
        except json.JSONDecodeError as e:
            self.logger.error(f"Invalid JSON in cookies file: {e}")
            return None
        except Exception as e:
            self.logger.error(f"Failed to load cookies: {e}")
            return None

    def save_if_updated(self, context):
        """æ£€æŸ¥å¹¶ä¿å­˜æ›´æ–°åçš„cookies"""
        try:
            current_cookies = context.cookies()
            nga_passport = next(
                (c for c in current_cookies if c['name'] == 'ngaPassportUid'),
                None
            )

            if nga_passport:
                old_passport = next(
                    (c for c in self.cookies if c['name'] == 'ngaPassportUid'),
                    None
                ) if self.cookies else None

                needs_update = (
                    not old_passport or
                    old_passport['value'] != nga_passport['value'] or
                    old_passport.get('expires', 0) != nga_passport.get('expires', 0)
                )

                if needs_update:
                    with open('cookies.txt', 'w', encoding='utf-8') as f:
                        json.dump(current_cookies, f, ensure_ascii=False, indent=2)

                    self.cookies = current_cookies
                    expires_time = time.strftime(
                        '%Y-%m-%d %H:%M:%S',
                        time.localtime(nga_passport['expires'])
                    )
                    self.logger.info(
                        f"âœ“ Updated ngaPassportUid: {nga_passport['value'][:20]}..., "
                        f"expires: {expires_time}"
                    )
        except Exception as e:
            self.logger.error(f"Auto-update cookies failed: {e}")


# ========== é¡µé¢è·å–å™¨ ==========
class PageFetcher:
    """é¡µé¢è·å–å™¨ - ä¼˜åŒ–ç‰ˆï¼šå•å®ä¾‹å¤šé¡µé¢å¤ç”¨"""
    def __init__(self, logger):
        self.logger = logger
        self._active_pages = {}  # ç¼“å­˜æ´»è·ƒé¡µé¢ï¼Œæ ¼å¼: {browser_index: page}
        self._page_lock = threading.Lock()  # é¡µé¢è®¿é—®é”
        self.debug_dir = 'debug_html'  # HTMLè°ƒè¯•æ–‡ä»¶ä¿å­˜ç›®å½•

    def fetch(self, browser_pool: List, url: str, cookies: Optional[List],
              browser_index: int, referer: str = 'https://bbs.nga.cn/') -> Dict:
        """è·å–é¡µé¢å†…å®¹ - å¤ç”¨é¡µé¢æé«˜æ•ˆç‡"""
        browser, context = browser_pool[browser_index % len(browser_pool)]

        # å°è¯•è·å–æˆ–åˆ›å»ºé¡µé¢
        page = None
        with self._page_lock:
            if browser_index in self._active_pages:
                page = self._active_pages[browser_index]
                self.logger.debug(f"Reusing page for browser {browser_index}")
            else:
                page = context.new_page()
                self._active_pages[browser_index] = page
                self.logger.debug(f"Created new page for browser {browser_index}")

        try:
            self.logger.debug(f"Loading page: {url} (browser {browser_index})")

            # åªåœ¨é¦–æ¬¡è®¿é—®æ—¶è®¾ç½®cookieï¼Œåç»­ä¿æŒä¼šè¯
            if cookies and len(context.cookies()) == 0:
                self.logger.debug(f"Setting {len(cookies)} cookies")
                context.add_cookies(cookies)
                time.sleep(0.1)

            page.set_extra_http_headers({'Referer': referer})

            self.logger.debug(f"Navigating to: {url}")
            nav_start = time.time()
            page.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
            nav_time = time.time() - nav_start
            self.logger.debug(f"Navigation complete: {nav_time:.2f}s")

            page.wait_for_load_state("domcontentloaded", timeout=LOAD_TIMEOUT)

            # è·å–é¡µé¢å†…å®¹
            page_content = page.content()

            # ğŸ” [DEBUG] æ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦å¼‚å¸¸
            content_length = len(page_content)
            self.logger.debug(f"ğŸ” [DEBUG] é¡µé¢å†…å®¹é•¿åº¦: {content_length} å­—ç¬¦")

            # å¦‚æœé¡µé¢å†…å®¹è¿‡çŸ­æˆ–å¼‚å¸¸ï¼Œä¿å­˜HTMLç”¨äºè°ƒè¯•
            if content_length < 1000:
                self.logger.warning(f"âš ï¸ [DEBUG] é¡µé¢å†…å®¹è¿‡çŸ­ ({content_length} å­—ç¬¦)ï¼Œå¯èƒ½æœªæ­£å¸¸åŠ è½½")
                self.save_html_debug_file(page_content, url, "content_too_short")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®å…ƒç´ 
            if 'bbs.nga.cn' not in page.url and 'nga' not in page_content.lower():
                self.logger.warning(f"âš ï¸ [DEBUG] é¡µé¢å¯èƒ½æœªæ­£ç¡®åŠ è½½NGAå†…å®¹")
                self.save_html_debug_file(page_content, url, "no_nga_content")

            # æ£€æŸ¥æ˜¯å¦æœ‰åçˆ¬è™«æç¤º
            if any(keyword in page_content for keyword in ['è®¿é—®è¿‡äºé¢‘ç¹', 'IPè¢«å°', 'éªŒè¯ç ', 'captcha', 'äººæœºéªŒè¯']):
                self.logger.warning(f"âš ï¸ [DEBUG] æ£€æµ‹åˆ°åçˆ¬è™«æˆ–éªŒè¯é¡µé¢")
                self.save_html_debug_file(page_content, url, "anti_bot")

            return {
                'url': page.url,
                'content': page_content,
                'success': True,
                'nav_time': nav_time,
                'content_length': content_length
            }
        except Exception as e:
            self.logger.error(f"Page load failed: {url}, error: {type(e).__name__}: {str(e)}")
            # å¦‚æœé¡µé¢å‡ºé”™ï¼Œå…³é—­å¹¶ç§»é™¤ç¼“å­˜
            with self._page_lock:
                if browser_index in self._active_pages:
                    try:
                        self._active_pages[browser_index].close()
                    except:
                        pass
                    del self._active_pages[browser_index]
            raise

    def close_all_pages(self):
        """å…³é—­æ‰€æœ‰ç¼“å­˜çš„é¡µé¢"""
        with self._page_lock:
            for page in self._active_pages.values():
                try:
                    page.close()
                except:
                    pass
            self._active_pages.clear()
            self.logger.info("All cached pages closed")

    def save_html_debug_file(self, content: str, url: str, reason: str = ""):
        """ä¿å­˜HTMLé¡µé¢åˆ°è°ƒè¯•æ–‡ä»¶"""
        import os
        import time

        # ç¡®ä¿è°ƒè¯•ç›®å½•å­˜åœ¨
        if not os.path.exists(self.debug_dir):
            os.makedirs(self.debug_dir)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
        # ä»URLä¸­æå–æœ‰ç”¨çš„éƒ¨åˆ†ä½œä¸ºæ–‡ä»¶å
        url_hash = hash(url) % 10000
        filename = f"{timestamp}_{url_hash}_{reason}.html"
        filepath = os.path.join(self.debug_dir, filename)

        try:
            # ä¿å­˜HTMLå†…å®¹
            with open(filepath, 'w', encoding='utf-8') as f:
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯åˆ°HTMLé¡¶éƒ¨
                debug_header = f"""
<!-- DEBUG INFO -->
<!-- URL: {url} -->
<!-- Timestamp: {timestamp} -->
<!-- Reason: {reason} -->
<!-- ======================= -->

"""
                f.write(debug_header)
                f.write(content)

            self.logger.info(f"ğŸ’¾ [DEBUG] HTMLå·²ä¿å­˜: {filepath}")
            return filepath
        except Exception as e:
            self.logger.error(f"âŒ [DEBUG] ä¿å­˜HTMLå¤±è´¥: {e}")
            return None


# ========== é”™è¯¯æŠ‘åˆ¶å·¥å…· ==========
class ErrorSuppressor:
    """ä¸´æ—¶æŠ‘åˆ¶é”™è¯¯è¾“å‡ºçš„å·¥å…·ç±»"""
    def __init__(self, logger=None):
        self.logger = logger
        self.original_stderr = None
        self.original_loglevel = None
        
    def __enter__(self):
        """è¿›å…¥ä¸Šä¸‹æ–‡æ—¶æŠ‘åˆ¶é”™è¯¯è¾“å‡º"""
        # ä¿å­˜åŸå§‹stderr
        self.original_stderr = sys.stderr
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„StringIOæ¥æ›¿ä»£stderr
        from io import StringIO
        sys.stderr = StringIO()
        
        # å¦‚æœæœ‰loggerï¼Œä¹Ÿä¸´æ—¶æé«˜æ—¥å¿—çº§åˆ«
        if self.logger:
            self.original_loglevel = self.logger.level
            self.logger.setLevel(logging.CRITICAL + 1)  # åªæ˜¾ç¤ºCRITICALä»¥ä¸Šçš„æ—¥å¿—
            
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡æ—¶æ¢å¤é”™è¯¯è¾“å‡º"""
        # æ¢å¤åŸå§‹stderr
        if self.original_stderr:
            sys.stderr = self.original_stderr
            
        # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
        if self.logger and self.original_loglevel is not None:
            self.logger.setLevel(self.original_loglevel)
            
        # å¦‚æœæœ‰greenleté”™è¯¯ï¼Œè®°å½•åˆ°æˆ‘ä»¬çš„loggerä¸­
        if exc_type and 'greenlet' in str(exc_type).lower():
            if self.logger:
                self.logger.debug(f"ğŸŸ¡ [é”™è¯¯æŠ‘åˆ¶] greenleté”™è¯¯å·²è¢«æŠ‘åˆ¶: {exc_type.__name__}: {exc_val}")


# ========== Playwrightå·¥ä½œçº¿ç¨‹ ==========
class PlaywrightWorker:
    """Playwrightä¸“ç”¨å·¥ä½œçº¿ç¨‹ï¼ˆè´Ÿè´£æµè§ˆå™¨æ± ç®¡ç†ï¼‰"""
    def __init__(self, max_browsers: int, proxy_manager=None, logger=None):
        self.max_browsers = max_browsers
        self.proxy_manager = proxy_manager
        self.logger = logger or self._default_logger
        self._workers = []
        self._task_queue = Queue()
        self._result_map = {}
        self._condition = threading.Condition(threading.Lock())
        self._stop_event = threading.Event()
        self._initialized = threading.Event()
        self._browser_pool = []
        self._playwright = None
        self._start_worker()

    def _default_logger(self):
        import logging
        return logging.getLogger('PlaywrightWorker')

    def _start_worker(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        worker = threading.Thread(
            target=self._playwright_worker_loop,
            name="PlaywrightWorker",
            daemon=False  # éå®ˆæŠ¤çº¿ç¨‹ï¼Œç¡®ä¿æ­£ç¡®å…³é—­
        )
        worker.start()
        self._workers.append(worker)

        # ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
        self._initialized.wait(timeout=10)

    def _create_browser_pool(self):
        """åœ¨å·¥ä½œçº¿ç¨‹ä¸­åˆ›å»ºæµè§ˆå™¨æ± """
        playwright = sync_playwright().start()

        for _ in range(self.max_browsers):
            browser = playwright.chromium.launch(
                headless=True,
                args=BROWSER_ARGS
            )

            context_kwargs = {
                'viewport': DEFAULT_VIEWPORT,
                'java_script_enabled': True,
                'ignore_https_errors': True,
                'permissions': [],
                'extra_http_headers': DEFAULT_HEADERS.copy()
            }

            if self.proxy_manager:
                proxy_dict = self.proxy_manager.get_random_proxy(mark_used=False)
                if proxy_dict and proxy_dict.get('proxy'):
                    proxy_server = proxy_dict['proxy']
                    proxy_config = {
                        'server': proxy_server,
                        'bypass': 'localhost;127.0.0.1;*.nga.cn;*.ngabbs.com'
                    }

                    if 'username' in proxy_dict and 'password' in proxy_dict:
                        proxy_config['username'] = proxy_dict['username']
                        proxy_config['password'] = proxy_dict['password']

                    context_kwargs['proxy'] = proxy_config
                    self.logger.debug(f"Using proxy: {proxy_server}")

            context = browser.new_context(**context_kwargs)
            self._browser_pool.append((browser, context))

        return playwright

    def _playwright_worker_loop(self):
        """Playwrightå·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯"""
        try:
            self.logger.info("Initializing Playwright worker...")
            self._playwright = self._create_browser_pool()
            self.logger.info(f"Browser pool initialized: {len(self._browser_pool)} instances")

            # é€šçŸ¥åˆå§‹åŒ–å®Œæˆ
            self._initialized.set()

            # å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯
            last_queue_check = time.time()
            while not self._stop_event.is_set():
                try:
                    request_id, task_func, args, kwargs, result_event = \
                        self._task_queue.get(timeout=0.1)

                    if self._stop_event.is_set():
                        if result_event:
                            result_event.set()
                        break

                    # ã€è¯Šæ–­æ—¥å¿—ã€‘è®°å½•ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
                    current_time = time.time()
                    if current_time - last_queue_check > 10:  # æ¯10ç§’è®°å½•ä¸€æ¬¡
                        queue_size = self._task_queue.qsize()
                        self.logger.info(f"ğŸ“Š [å·¥ä½œçº¿ç¨‹è¯Šæ–­] ä»»åŠ¡é˜Ÿåˆ—å¤§å°: {queue_size}")
                        last_queue_check = current_time

                    task_start = time.time()
                    try:
                        # åœ¨å·¥ä½œçº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡
                        task_name = getattr(task_func, '__name__', 'unknown_task')
                        self.logger.debug(f"ğŸ”„ [å·¥ä½œçº¿ç¨‹] å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_name}")
                        
                        result = task_func(self._browser_pool, *args, **kwargs)
                        
                        task_duration = time.time() - task_start
                        self.logger.debug(f"âœ… [å·¥ä½œçº¿ç¨‹] ä»»åŠ¡å®Œæˆ: {task_name}, è€—æ—¶: {task_duration:.2f}s")
                        
                        with self._condition:
                            self._result_map[request_id] = ('success', result, None)
                    except Exception as e:
                        task_duration = time.time() - task_start
                        self.logger.error(f"âŒ [å·¥ä½œçº¿ç¨‹] ä»»åŠ¡å¤±è´¥: {task_name}, è€—æ—¶: {task_duration:.2f}s, é”™è¯¯: {e}")
                        import traceback
                        with self._condition:
                            self._result_map[request_id] = ('error', None, (type(e), e, traceback.format_exc()))
                    finally:
                        with self._condition:
                            self._condition.notify_all()

                    if result_event:
                        result_event.set()
                except Empty:
                    continue
                except Exception as e:
                    self.logger.error(f"Worker error: {e}")

            # æ¸…ç†èµ„æº
            self.logger.info("ğŸ›‘ [è¯Šæ–­] å¼€å§‹å…³é—­æµè§ˆå™¨å®ä¾‹...")
            self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å½“å‰çº¿ç¨‹ID: {threading.get_ident()}")
            self.logger.info(f"ğŸ›‘ [è¯Šæ–­] æµè§ˆå™¨æ± å¤§å°: {len(self._browser_pool)}")
            
            # ã€è§£å†³æ–¹æ¡ˆã€‘æ›´å®‰å…¨çš„æµè§ˆå™¨å®ä¾‹å…³é—­é€»è¾‘
            for i, (browser, context) in enumerate(self._browser_pool):
                try:
                    self.logger.info(f"ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] å…³é—­æµè§ˆå™¨å®ä¾‹ {i}/{len(self._browser_pool)}")
                    
                    # ã€è§£å†³æ–¹æ¡ˆã€‘å…ˆå…³é—­æ‰€æœ‰é¡µé¢ï¼Œé¿å…ä¸Šä¸‹æ–‡å…³é—­æ—¶çš„å†²çª
                    try:
                        pages = context.pages
                        self.logger.info(f"ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] å…³é—­å®ä¾‹ {i} çš„ {len(pages)} ä¸ªé¡µé¢...")
                        for page in pages:
                            # ã€æ ¹æœ¬è§£å†³æ–¹æ¡ˆã€‘ä½¿ç”¨é”™è¯¯æŠ‘åˆ¶å™¨å®Œå…¨æ¶ˆé™¤greenleté”™è¯¯è¾“å‡º
                            with ErrorSuppressor(self.logger):
                                try:
                                    page.close()
                                    # ã€è§£å†³æ–¹æ¡ˆã€‘å¢åŠ å»¶è¿Ÿï¼Œè®©greenletæœ‰æ—¶é—´å®Œæˆåˆ‡æ¢
                                    time.sleep(0.05)
                                except Exception as page_e:
                                    error_type = type(page_e).__name__
                                    if 'greenlet' in error_type.lower():
                                        self.logger.debug(f"ğŸŸ¡ [æ ¹æœ¬è§£å†³æ–¹æ¡ˆ] å…³é—­é¡µé¢æ—¶æ£€æµ‹åˆ°greenleté”™è¯¯ï¼ˆå·²æŠ‘åˆ¶ï¼‰: {page_e}")
                                    else:
                                        self.logger.warning(f"ğŸŸ¡ [è§£å†³æ–¹æ¡ˆ] å…³é—­é¡µé¢æ—¶å‡ºé”™ï¼ˆå¿½ç•¥ï¼‰: {page_e}")
                    except Exception as pages_e:
                        self.logger.warning(f"ğŸŸ¡ [è§£å†³æ–¹æ¡ˆ] è·å–é¡µé¢åˆ—è¡¨æ—¶å‡ºé”™ï¼ˆå¿½ç•¥ï¼‰: {pages_e}")
                    
                    # ã€è§£å†³æ–¹æ¡ˆã€‘å¢åŠ å»¶è¿Ÿï¼Œè®©greenletæœ‰æ—¶é—´å®Œæˆåˆ‡æ¢
                    time.sleep(0.2)
                    
                    self.logger.info(f"ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] å…³é—­ä¸Šä¸‹æ–‡...")
                    # ã€æ ¹æœ¬è§£å†³æ–¹æ¡ˆã€‘ä½¿ç”¨é”™è¯¯æŠ‘åˆ¶å™¨å®Œå…¨æ¶ˆé™¤greenleté”™è¯¯è¾“å‡º
                    with ErrorSuppressor(self.logger):
                        try:
                            context.close()
                        except Exception as ctx_e:
                            error_type = type(ctx_e).__name__
                            if 'greenlet' in error_type.lower():
                                self.logger.debug(f"ğŸŸ¡ [æ ¹æœ¬è§£å†³æ–¹æ¡ˆ] å…³é—­ä¸Šä¸‹æ–‡æ—¶æ£€æµ‹åˆ°greenleté”™è¯¯ï¼ˆå·²æŠ‘åˆ¶ï¼‰: {ctx_e}")
                            else:
                                self.logger.error(f"âŒ [è§£å†³æ–¹æ¡ˆ] å…³é—­ä¸Šä¸‹æ–‡å¤±è´¥: {ctx_e}")
                    
                    # ã€è§£å†³æ–¹æ¡ˆã€‘å†æ¬¡å¢åŠ å»¶è¿Ÿ
                    time.sleep(0.2)
                    
                    self.logger.info(f"ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] å…³é—­æµè§ˆå™¨...")
                    # ã€æ ¹æœ¬è§£å†³æ–¹æ¡ˆã€‘ä½¿ç”¨é”™è¯¯æŠ‘åˆ¶å™¨å®Œå…¨æ¶ˆé™¤greenleté”™è¯¯è¾“å‡º
                    with ErrorSuppressor(self.logger):
                        try:
                            browser.close()
                            self.logger.info(f"âœ… [è§£å†³æ–¹æ¡ˆ] æµè§ˆå™¨å®ä¾‹ {i} å…³é—­æˆåŠŸ")
                            
                            # ã€è§£å†³æ–¹æ¡ˆã€‘åœ¨æµè§ˆå™¨å®ä¾‹ä¹‹é—´å¢åŠ å»¶è¿Ÿï¼Œç¡®ä¿å®Œå…¨å…³é—­
                            if i < len(self._browser_pool) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªå®ä¾‹
                                time.sleep(0.3)
                        except Exception as browser_e:
                            error_type = type(browser_e).__name__
                            if 'greenlet' in error_type.lower():
                                self.logger.debug(f"ğŸŸ¡ [æ ¹æœ¬è§£å†³æ–¹æ¡ˆ] å…³é—­æµè§ˆå™¨æ—¶æ£€æµ‹åˆ°greenleté”™è¯¯ï¼ˆå·²æŠ‘åˆ¶ï¼‰: {browser_e}")
                            else:
                                self.logger.error(f"âŒ [è§£å†³æ–¹æ¡ˆ] å…³é—­æµè§ˆå™¨å¤±è´¥: {browser_e}")
                    
                except Exception as e:
                    # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    error_type = type(e).__name__
                    error_msg = str(e)
                    self.logger.error(f"âŒ [è§£å†³æ–¹æ¡ˆ] å…³é—­æµè§ˆå™¨å®ä¾‹ {i} å¤±è´¥: {error_type}: {error_msg}")
                    
                    # ã€è§£å†³æ–¹æ¡ˆã€‘æ”¹è¿›greenleté”™è¯¯å¤„ç†
                    if 'greenlet' in error_type.lower():
                        self.logger.warning(f"ğŸŸ¡ [è§£å†³æ–¹æ¡ˆ] æ£€æµ‹åˆ°greenleté”™è¯¯ï¼Œè¿™é€šå¸¸æ˜¯Playwrightå…³é—­æ—¶çš„æ­£å¸¸ç°è±¡")
                        self.logger.info(f"ğŸŸ¡ [è§£å†³æ–¹æ¡ˆ] greenleté”™è¯¯ä¸ä¼šå½±å“åŠŸèƒ½ï¼Œç»§ç»­å…³é—­å…¶ä»–å®ä¾‹...")
                        import traceback
                        self.logger.debug(f"ğŸŸ¡ [è§£å†³æ–¹æ¡ˆ] greenleté”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
                    else:
                        self.logger.error(f"âŒ [è§£å†³æ–¹æ¡ˆ] égreenleté”™è¯¯å…³é—­æµè§ˆå™¨: {e}")

            # ã€è§£å†³æ–¹æ¡ˆã€‘å¢åŠ å»¶è¿Ÿï¼Œç¡®ä¿æ‰€æœ‰æµè§ˆå™¨å®ä¾‹å®Œå…¨å…³é—­
            time.sleep(0.5)

            if self._playwright:
                try:
                    self.logger.info(f"ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] åœæ­¢Playwright...")
                    # ã€è§£å†³æ–¹æ¡ˆã€‘å¢åŠ å»¶è¿Ÿï¼Œç¡®ä¿æ‰€æœ‰æµè§ˆå™¨å®ä¾‹å®Œå…¨å…³é—­
                    time.sleep(0.5)
                    
                    # ã€æ ¹æœ¬è§£å†³æ–¹æ¡ˆã€‘ä½¿ç”¨é”™è¯¯æŠ‘åˆ¶å™¨å®Œå…¨æ¶ˆé™¤greenleté”™è¯¯è¾“å‡º
                    with ErrorSuppressor(self.logger):
                        self._playwright.stop()
                    self.logger.info(f"âœ… [è§£å†³æ–¹æ¡ˆ] Playwrightåœæ­¢æˆåŠŸ")
                except Exception as e:
                    error_type = type(e).__name__
                    error_msg = str(e)
                    self.logger.error(f"âŒ [è§£å†³æ–¹æ¡ˆ] åœæ­¢Playwrightå¤±è´¥: {error_type}: {error_msg}")
                    
                    # ã€è§£å†³æ–¹æ¡ˆã€‘æ”¹è¿›greenleté”™è¯¯å¤„ç†
                    if 'greenlet' in error_type.lower():
                        self.logger.debug(f"ğŸŸ¡ [æ ¹æœ¬è§£å†³æ–¹æ¡ˆ] Playwrightåœæ­¢æ—¶æ£€æµ‹åˆ°greenleté”™è¯¯ï¼ˆå·²æŠ‘åˆ¶ï¼‰: {e}")
                    else:
                        self.logger.error(f"âŒ [è§£å†³æ–¹æ¡ˆ] égreenleté”™è¯¯åœæ­¢Playwright: {e}")

            self.logger.info("âœ… [è§£å†³æ–¹æ¡ˆ] Playwright worker stopped")

        except Exception as e:
            self.logger.error(f"Playwright worker failed: {e}")
            self._initialized.set()  # ç¡®ä¿é€šçŸ¥ç­‰å¾…è€…
            raise

    def execute(self, task_func: Callable, *args, **kwargs):
        """åœ¨å·¥ä½œçº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡"""
        if self._stop_event.is_set():
            raise InterruptedError("Playwright worker is shutting down")

        request_id = str(uuid.uuid4())
        result_event = threading.Event()
        task_name = getattr(task_func, '__name__', str(task_func))

        with self._condition:
            self._result_map[request_id] = None

        self._task_queue.put((request_id, task_func, args, kwargs, result_event))
        self.logger.debug(f"Task queued: {task_name}")

        # ç­‰å¾…ç»“æœ
        if not result_event.wait(timeout=REQUEST_TIMEOUT):
            with self._condition:
                self._result_map.pop(request_id, None)
            raise TimeoutError(f"Task timeout: {task_name}")

        with self._condition:
            status, result, error = self._result_map.pop(request_id, ('timeout', None, 'Timeout'))

            if status == 'success':
                self.logger.debug(f"Task completed: {task_name}")
                return result
            elif status == 'error':
                exc_type, exc_value, _ = error
                self.logger.error(f"Task failed: {task_name}, {exc_type.__name__}: {exc_value}")
                raise exc_type(exc_value)
            else:
                self.logger.error(f"Task timeout: {task_name}")
                raise TimeoutError(f"Task timeout: {task_name}")

    def shutdown(self, timeout: int = 10):
        """å…³é—­å·¥ä½œçº¿ç¨‹"""
        self.logger.info("ğŸ›‘ [è¯Šæ–­] å¼€å§‹å…³é—­ Playwright worker...")
        self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å½“å‰çº¿ç¨‹ID: {threading.get_ident()}")
        self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å·¥ä½œçº¿ç¨‹æ•°é‡: {len(self._workers)}")
        
        # ã€è§£å†³æ–¹æ¡ˆã€‘å…ˆè®¾ç½®åœæ­¢æ ‡å¿—ï¼Œç„¶åç­‰å¾…å·¥ä½œçº¿ç¨‹è‡ªç„¶ç»“æŸ
        self._stop_event.set()
        
        # ã€è§£å†³æ–¹æ¡ˆã€‘ç»™å·¥ä½œçº¿ç¨‹æ›´å¤šæ—¶é—´å®Œæˆå½“å‰ä»»åŠ¡ï¼Œé¿å…å¼ºåˆ¶ä¸­æ–­
        self.logger.info("ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] ç­‰å¾…å·¥ä½œçº¿ç¨‹å®Œæˆå½“å‰ä»»åŠ¡...")
        time.sleep(2)  # ç»™å·¥ä½œçº¿ç¨‹2ç§’æ—¶é—´å®Œæˆå½“å‰ä»»åŠ¡
        
        # ã€è¯Šæ–­æ—¥å¿—ã€‘è®°å½•æ¯ä¸ªå·¥ä½œçº¿ç¨‹çš„çŠ¶æ€
        for i, worker in enumerate(self._workers):
            self.logger.info(f"ğŸ›‘ [è¯Šæ–­] ç­‰å¾…å·¥ä½œçº¿ç¨‹ {i} (ID: {worker.ident}) é€€å‡º...")
            if worker.is_alive():
                self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å·¥ä½œçº¿ç¨‹ {i} ä»åœ¨è¿è¡Œï¼Œç­‰å¾…åŠ å…¥...")
            else:
                self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å·¥ä½œçº¿ç¨‹ {i} å·²åœæ­¢")
                
            worker.join(timeout=timeout)
            
            if worker.is_alive():
                self.logger.warning(f"ğŸ›‘ [è¯Šæ–­] å·¥ä½œçº¿ç¨‹ {i} ä»åœ¨è¿è¡Œï¼Œå¯èƒ½æœªæ­£ç¡®å…³é—­")
            else:
                self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å·¥ä½œçº¿ç¨‹ {i} å·²æˆåŠŸå…³é—­")

        self.logger.info("âœ… [è¯Šæ–­] Playwright worker shutdown å®Œæˆ")


# ========== æµè§ˆå™¨æ±  ==========
class BrowserPool:
    """æµè§ˆå™¨è¿æ¥æ± ï¼ˆä½¿ç”¨PlaywrightWorkerï¼‰"""
    def __init__(self, max_browsers: int = 2, proxy_manager=None, logger=None):
        self.max_browsers = max_browsers
        self.proxy_manager = proxy_manager
        self.logger = logger or self._default_logger
        self.stats = PerformanceStats()
        self._page_fetcher = PageFetcher(self.logger)
        self._playwright_worker = PlaywrightWorker(max_browsers, proxy_manager, logger)

    def _default_logger(self):
        import logging
        return logging.getLogger('BrowserPool')

    def fetch_page(self, url: str, cookies: Optional[List],
                   browser_index: int) -> Dict:
        """è·å–é¡µé¢"""
        def _fetch_task(browser_pool):
            return self._page_fetcher.fetch(browser_pool, url, cookies, browser_index)

        return self._playwright_worker.execute(_fetch_task)

    def log_pool_status(self):
        """è®°å½•è¿æ¥æ± çŠ¶æ€"""
        stats = self.stats.get_stats()
        report = "\n".join([f"{k}: {v}" for k, v in stats.items()])
        self.logger.info(f"Performance stats:\n{report}")

    def close(self):
        """å…³é—­æµè§ˆå™¨æ± """
        self.logger.info("ğŸ›‘ [è¯Šæ–­] å¼€å§‹å…³é—­æµè§ˆå™¨æ± ...")
        self.logger.info(f"ğŸ›‘ [è¯Šæ–­] å…³é—­æµè§ˆå™¨æ± çš„çº¿ç¨‹ID: {threading.get_ident()}")
        
        # å…ˆå…³é—­ç¼“å­˜çš„é¡µé¢
        self.logger.info("ğŸ›‘ [è¯Šæ–­] å…³é—­ç¼“å­˜çš„é¡µé¢...")
        self._page_fetcher.close_all_pages()
        
        self.logger.info("ğŸ›‘ [è¯Šæ–­] å…³é—­Playwright worker...")
        self._playwright_worker.shutdown()
        
        self.log_pool_status()
        self.logger.info("âœ… [è¯Šæ–­] æµè§ˆå™¨æ± å…³é—­å®Œæˆ")


# ========== Playwrightä¸­é—´ä»¶ ==========
class PlaywrightMiddleware:
    """ä¼˜åŒ–çš„Playwrightä¸­é—´ä»¶"""
    def __init__(self):
        self.browser_pool = None
        self.logger = None
        self.cookie_manager = None
        self.proxy_manager = None
        self.ban_detector = None
        self.instance_manager = None
        self.last_stat_time = time.time()
        self._browser_index = 0
        self._failed_browsers = {}
        self._lock = threading.Lock()

    @classmethod
    def from_crawler(cls, crawler):
        if not crawler.settings.getbool('PLAYWRIGHT_ENABLED', True):
            raise NotConfigured('Playwright middleware not enabled')

        middleware = cls()
        crawler.signals.connect(middleware.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(middleware.spider_closed, signal=signals.spider_closed)
        return middleware

    def spider_opened(self, spider):
        """Spiderå¯åŠ¨å¤„ç†"""
        self.logger = spider.logger
        self.logger.info("=" * 60)
        self.logger.info("Playwright middleware starting")
        self.logger.info("=" * 60)

        # åˆå§‹åŒ–Cookieç®¡ç†å™¨
        self.cookie_manager = CookieManager(self.logger)
        self.cookie_manager.load()

        # åˆå§‹åŒ–å°ç¦æ£€æµ‹å™¨
        self.ban_detector = BanDetector(
            logger=self.logger,
            ban_threshold=spider.settings.getint('BAN_THRESHOLD', 3),
            recovery_time=spider.settings.getint('BAN_RECOVERY_TIME', 1800)
        )

        # åˆå§‹åŒ–å®ä¾‹ç®¡ç†å™¨
        def replace_instance(failed_id: int) -> int:
            return self._replace_browser_instance(failed_id)

        self.instance_manager = BrowserInstanceManager(
            max_instances=spider.settings.getint('PLAYWRIGHT_POOL_SIZE', 2),
            ban_detector=self.ban_detector,
            replacement_callback=replace_instance,
            proxy_manager=self.proxy_manager,
            logger=self.logger
        )

        self.instance_manager.start()
        self.logger.info("Ban detection and instance manager started")

        # åˆå§‹åŒ–ä»£ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        proxy_enabled = spider.settings.getbool('PROXY_ENABLED', False)
        if proxy_enabled:
            self._init_proxy(spider)
        else:
            self.logger.info("Proxy disabled")

        self.logger.info("=" * 60)

    def _init_proxy(self, spider):
        """åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨"""
        try:
            self.logger.info("Initializing proxy manager...")
            self.proxy_manager = get_proxy_manager()
            proxies = self.proxy_manager.get_proxies(force_refresh=True)

            if proxies:
                self.logger.info(f"Loaded {len(proxies)} proxies")
            else:
                self.logger.warning("No proxies loaded")

            status = self.proxy_manager.get_pool_status()
            self.logger.info("Proxy pool status:")
            for key, value in status.items():
                self.logger.info(f"  - {key}: {value}")
        except FileNotFoundError:
            self.logger.error("Proxy config file not found")
            self.proxy_manager = None
        except ValueError as e:
            self.logger.error(f"Proxy config validation error: {e}")
            self.proxy_manager = None
        except Exception as e:
            self.logger.error(f"Proxy manager init failed: {e}")
            self.proxy_manager = None

    def spider_closed(self, spider, reason):
        """Spiderå…³é—­å¤„ç†"""
        self.logger.info(f"ğŸ›‘ [è¯Šæ–­] Spiderå…³é—­å¤„ç†å¼€å§‹: {reason}")
        self.logger.info(f"ğŸ›‘ [è¯Šæ–­] spider_closedçº¿ç¨‹ID: {threading.get_ident()}")

        # ã€è§£å†³æ–¹æ¡ˆã€‘æŒ‰é¡ºåºå…³é—­ï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
        # 1. é¦–å…ˆåœæ­¢å®ä¾‹ç®¡ç†å™¨ï¼Œé˜²æ­¢å…¶ç»§ç»­æ“ä½œæµè§ˆå™¨å®ä¾‹
        if self.instance_manager:
            self.logger.info("ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] ç¬¬1æ­¥: åœæ­¢å®ä¾‹ç®¡ç†å™¨...")
            self.instance_manager.stop()
            self.logger.info("âœ… [è§£å†³æ–¹æ¡ˆ] å®ä¾‹ç®¡ç†å™¨åœæ­¢å®Œæˆ")
            # ç­‰å¾…ä¸€ç§’ç¡®ä¿æ‰€æœ‰çº¿ç¨‹å®Œå…¨åœæ­¢
            time.sleep(1)

        # 2. ç„¶åå…³é—­æµè§ˆå™¨æ± ï¼Œæ­¤æ—¶æ²¡æœ‰å…¶ä»–çº¿ç¨‹åœ¨æ“ä½œæµè§ˆå™¨
        if self.browser_pool:
            self.logger.info("ğŸ›‘ [è§£å†³æ–¹æ¡ˆ] ç¬¬2æ­¥: å…³é—­æµè§ˆå™¨æ± ...")
            self.browser_pool.close()
            self.logger.info("âœ… [è§£å†³æ–¹æ¡ˆ] æµè§ˆå™¨æ± å…³é—­å®Œæˆ")
            
        self.logger.info("âœ… [è§£å†³æ–¹æ¡ˆ] Spiderå…³é—­å¤„ç†å®Œæˆ")

    def process_request(self, request, spider):
        """å¤„ç†è¯·æ±‚"""
        self.logger = spider.logger

        # ã€æ–°å¢è°ƒè¯•ã€‘è®°å½•æ¯ä¸ªè¢«è°ƒç”¨çš„è¯·æ±‚
        if 'read.php' in request.url:
            self.logger.debug(f"ğŸ” [Middleware] æ”¶åˆ°è¯·æ±‚: {request.url}, Priority: {request.priority}")
            # ã€è¯Šæ–­æ—¥å¿—ã€‘æ£€æŸ¥è°ƒåº¦é˜Ÿåˆ—çŠ¶æ€
            if hasattr(spider.crawler.engine, 'scheduler') and hasattr(spider.crawler.engine.scheduler, 'queue'):
                queue_size = len(spider.crawler.engine.scheduler.queue)
                self.logger.info(f"ğŸ“Š [é˜Ÿåˆ—è¯Šæ–­] å½“å‰è°ƒåº¦é˜Ÿåˆ—é•¿åº¦: {queue_size}")

        # ç»Ÿè®¡æŠ¥å‘Š
        if time.time() - self.last_stat_time > 300:
            if self.browser_pool:
                self.browser_pool.log_pool_status()
            if self.instance_manager:
                self.logger.info(self.instance_manager.get_status_report())
            self.last_stat_time = time.time()

        # è·³è¿‡å›¾ç‰‡è¯·æ±‚
        if 'jpg' in request.url:
            return None

        try:
            # ç¡®ä¿æµè§ˆå™¨æ± å·²åˆå§‹åŒ–
            if not self.browser_pool:
                self.browser_pool = BrowserPool(
                    max_browsers=spider.settings.getint('PLAYWRIGHT_POOL_SIZE', 2),
                    proxy_manager=self.proxy_manager,
                    logger=self.logger
                )

            # è·å–å¯ç”¨æµè§ˆå™¨å®ä¾‹
            browser_index = self._select_browser_instance()
            if browser_index is None:
                self.logger.error("No available browser instances")
                return None

            # å°è¯•è·å–é¡µé¢ï¼ˆæœ€å¤š3æ¬¡ï¼‰
            for attempt in range(3):
                try:
                    # ã€è¯Šæ–­æ—¥å¿—ã€‘è®°å½•é¡µé¢è·å–å¼€å§‹
                    self.logger.info(f"ğŸš€ [é¡µé¢è·å–] å¼€å§‹è·å–é¡µé¢: {request.url[:80]}... (æµè§ˆå™¨å®ä¾‹: {browser_index}, å°è¯•: {attempt + 1}/3)")
                    
                    start_time = time.time()
                    result = self.browser_pool.fetch_page(
                        request.url, self.cookie_manager.cookies, browser_index
                    )
                    response_time = time.time() - start_time

                    # è®°å½•æˆåŠŸ
                    self.browser_pool.stats.log_request(True, response_time)
                    if self.instance_manager:
                        self.instance_manager.report_success(browser_index, response_time)

                    self.logger.info(f"âœ… [é¡µé¢è·å–æˆåŠŸ] {request.url[:80]}... ({response_time:.2f}s)")
                    self.logger.info(f"  ğŸ” [DEBUG] å†…å®¹é•¿åº¦: {result.get('content_length', 0)} å­—ç¬¦")

                    # åˆ›å»ºå“åº”å¯¹è±¡
                    response = scrapy.http.HtmlResponse(
                        url=result['url'],
                        body=result['content'].encode('utf-8'),
                        encoding='utf-8',
                        request=request,
                        status=200  # æ˜ç¡®è®¾ç½®çŠ¶æ€ç 
                    )

                    # ğŸ” [DEBUG] åœ¨è¿”å›å“åº”å‰æ£€æŸ¥å†…å®¹
                    if result.get('content_length', 0) < 1000:
                        self.logger.warning(f"âš ï¸ [DEBUG] å“åº”å†…å®¹è¿‡çŸ­ï¼Œä¿å­˜HTMLç”¨äºè°ƒè¯•")
                        if hasattr(self, '_page_fetcher'):
                            self._page_fetcher.save_html_debug_file(
                                result['content'],
                                request.url,
                                "response_too_short"
                            )

                    return response

                except (PlaywrightTimeoutError, Exception) as e:
                    error_type = type(e).__name__

                    # æŠ¥å‘Šå¤±è´¥
                    is_banned = False
                    if self.instance_manager:
                        is_banned = self.instance_manager.report_failure(browser_index, e)

                    with self._lock:
                        self._failed_browsers[browser_index] = time.time()

                    self.logger.warning(
                        f"Browser {browser_index} failed (attempt {attempt + 1}/3): "
                        f"{error_type}: {str(e)[:100]}..."
                    )

                    if is_banned:
                        self.logger.warning(f"Browser {browser_index} banned, will be replaced")

                    # é€‰æ‹©ä¸‹ä¸€ä¸ªå®ä¾‹
                    browser_index = self._select_browser_instance()
                    if browser_index is None:
                        break

                    # å°è¯•ä¸‹ä¸€ä¸ªå®ä¾‹
                    continue

            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
            self.browser_pool.stats.log_timeout()
            return scrapy.http.Response(
                url=request.url,
                status=408,
                body=b'',
                headers={'Retry-After': '30'}
            )

        except Exception as e:
            self.logger.error(f"Request processing failed: {e}")
            return None

    def _select_browser_instance(self) -> Optional[int]:
        """é€‰æ‹©å¯ç”¨çš„æµè§ˆå™¨å®ä¾‹"""
        pool_size = self.browser_pool.max_browsers if self.browser_pool else 1

        # é¦–å…ˆå°è¯•ä½¿ç”¨å®ä¾‹ç®¡ç†å™¨æ¨èçš„å®ä¾‹
        if self.instance_manager:
            selected = self.instance_manager.get_available_instance_id()
            if selected is not None and selected not in self.ban_detector.browser_instances:
                proxy_addr = None
                if self.proxy_manager:
                    try:
                        proxy_dict = self.proxy_manager.get_random_proxy(mark_used=False)
                        proxy_addr = proxy_dict.get('proxy') if proxy_dict else None
                    except:
                        pass
                self.instance_manager.register_instance(selected, proxy_addr)

                if not self.ban_detector.is_instance_banned(selected):
                    # æ£€æŸ¥å¤±è´¥é»‘åå•
                    with self._lock:
                        if selected not in self._failed_browsers or \
                           time.time() - self._failed_browsers[selected] >= 300:
                            return selected

        # è½®è¯¢é€‰æ‹©
        for _ in range(pool_size):
            idx = self._browser_index % pool_size
            self._browser_index += 1

            # æ£€æŸ¥å°ç¦çŠ¶æ€
            if self.ban_detector.is_instance_banned(idx):
                continue

            # æ£€æŸ¥å¤±è´¥é»‘åå•
            with self._lock:
                if idx in self._failed_browsers:
                    if time.time() - self._failed_browsers[idx] < 300:
                        continue
                    else:
                        del self._failed_browsers[idx]

            # æ³¨å†Œå®ä¾‹
            if self.instance_manager and idx not in self.ban_detector.browser_instances:
                proxy_addr = None
                if self.proxy_manager:
                    try:
                        proxy_dict = self.proxy_manager.get_random_proxy(mark_used=False)
                        proxy_addr = proxy_dict.get('proxy') if proxy_dict else None
                    except:
                        pass
                self.instance_manager.register_instance(idx, proxy_addr)

            return idx

        return None

    def _replace_browser_instance(self, failed_instance_id: int) -> Optional[int]:
        """æ›¿æ¢å¤±è´¥çš„æµè§ˆå™¨å®ä¾‹"""
        self.logger.info(f"Replacing browser instance {failed_instance_id}")
        return (failed_instance_id + 1000) % 10000

    def close_spider(self, spider):
        """å…³é—­Spider"""
        if self.browser_pool:
            self.browser_pool.close()
